#!/bin/bash
set -e

# Simplified ComfyUI Model Installer - Fixes syntax error issues
# This version uses a simpler approach to parallel downloading
echo "=== ComfyUI Enhanced Model Downloader (Simplified Version) ==="

# Get the directory where the script is located
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# Default values
TEST_MODE=false
COMFYUI_DIR=""
VERBOSE=false
FAILED_MODE=false

# Parse command-line arguments
for arg in "$@"; do
  if [ "$arg" = "--test" ]; then
    TEST_MODE=true
  elif [ "$arg" = "--verbose" ] || [ "$arg" = "-v" ]; then
    VERBOSE=true
  elif [ "$arg" = "--failed" ]; then
    FAILED_MODE=true
  elif [ "$arg" != "--test" ] && [ "$arg" != "--verbose" ] && [ "$arg" != "-v" ] && [ "$arg" != "--failed" ]; then
    COMFYUI_DIR="$arg"
  fi
done

# If no directory was specified, use current directory
if [ -z "$COMFYUI_DIR" ]; then
  COMFYUI_DIR=$(pwd)
  echo "No directory specified, using current directory: $COMFYUI_DIR"
else
  echo "Using specified directory: $COMFYUI_DIR"
fi

# Determine optimal number of parallel downloads based on CPU cores
AVAILABLE_CORES=$(nproc 2>/dev/null || sysctl -n hw.ncpu 2>/dev/null || echo 4)
MAX_PARALLEL_DOWNLOADS=$((AVAILABLE_CORES * 3 / 4))
MAX_PARALLEL_DOWNLOADS=$((MAX_PARALLEL_DOWNLOADS < 4 ? 4 : MAX_PARALLEL_DOWNLOADS))
MAX_PARALLEL_DOWNLOADS=$((MAX_PARALLEL_DOWNLOADS > 32 ? 32 : MAX_PARALLEL_DOWNLOADS))

# Function to show progress
show_progress() {
  local msg="$1"
  echo ""
  echo "---------------------------------------------------"
  echo "  $msg"
  echo "---------------------------------------------------"
}

# Check if the specified directory is a ComfyUI directory (unless in test mode)
if [ "$TEST_MODE" = false ]; then
  if [ ! -d "$COMFYUI_DIR" ]; then
    echo "ERROR: The specified directory does not exist: $COMFYUI_DIR"
    echo "Creating it now..."
    mkdir -p "$COMFYUI_DIR"
  fi
fi

show_progress "Creating model directories"
# Create ALL required directories with error handling
mkdir -p "$COMFYUI_DIR/models/checkpoints" || echo "Warning: Could not create checkpoints directory"
mkdir -p "$COMFYUI_DIR/models/clip_vision" || echo "Warning: Could not create clip_vision directory"
mkdir -p "$COMFYUI_DIR/models/vae" || echo "Warning: Could not create vae directory"
mkdir -p "$COMFYUI_DIR/models/loras" || echo "Warning: Could not create loras directory"
mkdir -p "$COMFYUI_DIR/models/controlnet" || echo "Warning: Could not create controlnet directory"
mkdir -p "$COMFYUI_DIR/models/upscale_models" || echo "Warning: Could not create upscale_models directory"
mkdir -p "$COMFYUI_DIR/models/facerestore_models" || echo "Warning: Could not create facerestore_models directory"
mkdir -p "$COMFYUI_DIR/models/ipadapter" || echo "Warning: Could not create ipadapter directory"
mkdir -p "$COMFYUI_DIR/models/instantid/antelopev2" || echo "Warning: Could not create instantid/antelopev2 directory"
mkdir -p "$COMFYUI_DIR/models/insightface" || echo "Warning: Could not create insightface directory"
mkdir -p "$COMFYUI_DIR/models/ultralytics/bbox" || echo "Warning: Could not create ultralytics/bbox directory"
mkdir -p "$COMFYUI_DIR/models/sams" || echo "Warning: Could not create sams directory"
mkdir -p "$COMFYUI_DIR/models/reactor/faces" || echo "Warning: Could not create reactor/faces directory"
mkdir -p "$COMFYUI_DIR/models/reswapper" || echo "Warning: Could not create reswapper directory"

# Check for wget
if ! command -v wget &>/dev/null; then
  echo "ERROR: wget is not installed. Please install wget to use this script."
  echo "On Ubuntu/Debian: sudo apt-get install wget"
  echo "On CentOS/RHEL: sudo yum install wget"
  echo "On macOS with Homebrew: brew install wget"
  exit 1
fi

cd "$COMFYUI_DIR"

# ====================================================
# IPAdapter Special Case Handling - Processed Sequentially
# ====================================================
show_progress "Downloading IPAdapter models that require special naming"

# Array of source URLs and destination filenames
declare -a ipa_special_models=(
  "https://huggingface.co/h94/IP-Adapter/resolve/main/models/image_encoder/model.safetensors|models/clip_vision/CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors"
  "https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/image_encoder/model.safetensors|models/clip_vision/CLIP-ViT-bigG-14-laion2B-39B-b160k.safetensors"
  "https://huggingface.co/Kwai-Kolors/Kolors-IP-Adapter-Plus/resolve/main/image_encoder/pytorch_model.bin|models/clip_vision/clip-vit-large-patch14-336.bin"
  "https://huggingface.co/Kwai-Kolors/Kolors-IP-Adapter-Plus/resolve/main/ip_adapter_plus_general.bin|models/ipadapter/Kolors-IP-Adapter-Plus.bin"
  "https://huggingface.co/Kwai-Kolors/Kolors-IP-Adapter-FaceID-Plus/resolve/main/ipa-faceid-plus.bin|models/ipadapter/Kolors-IP-Adapter-FaceID-Plus.bin"
)

# Process each URL and destination pair sequentially
echo "Processing ${#ipa_special_models[@]} special case IPAdapter models sequentially..."

for pair in "${ipa_special_models[@]}"; do
  url=$(echo "$pair" | cut -d'|' -f1)
  dest=$(echo "$pair" | cut -d'|' -f2)

  # Get filename for better logging
  filename=$(basename "$dest")
  full_path="$COMFYUI_DIR/$dest"

  # Make sure the directory exists
  mkdir -p "$(dirname "$full_path")"

  echo "Downloading to $dest ..."
  if wget -q -c "$url" -O "$full_path" --show-progress; then
    echo "✓ $dest - Complete"
  else
    echo "✗ $dest - Failed"
    echo "  URL: $url"
  fi
done

echo "All IPAdapter special case models have been processed."

# ====================================================
# Main Model Downloads - Simplified approach
# ====================================================
show_progress "Starting main model downloads"
echo "Using $MAX_PARALLEL_DOWNLOADS parallel downloads (based on $AVAILABLE_CORES CPU cores)"

# Determine which file to use for downloads
if [ "$FAILED_MODE" = true ] && [ -f "$COMFYUI_DIR/failed_downloads.txt" ]; then
  DOWNLOAD_LIST="$COMFYUI_DIR/failed_downloads.txt"
  echo "Using failed_downloads.txt to retry failed downloads"
else
  # Check if download list exists
  DOWNLOAD_LIST="$SCRIPT_DIR/model_downloads.txt"
  if [ ! -f "$DOWNLOAD_LIST" ]; then
    echo "ERROR: $DOWNLOAD_LIST not found!"
    echo "Please ensure the model_downloads.txt file is in the same directory as this script."
    exit 1
  fi
fi

# Create temporary directories for tracking
TEMP_DIR=$(mktemp -d)
SUCCESS_DIR="$TEMP_DIR/success"
FAIL_DIR="$TEMP_DIR/fail"
LOG_DIR="$TEMP_DIR/logs"
SECTION_DIR="$TEMP_DIR/sections"
mkdir -p "$SUCCESS_DIR" "$FAIL_DIR" "$LOG_DIR" "$SECTION_DIR"

# Create a download script for each URL
DOWNLOAD_SCRIPT="$TEMP_DIR/download.sh"
cat >"$DOWNLOAD_SCRIPT" <<'EOF'
#!/bin/bash
url="$1"
dest="$2"
comfyui_dir="$3"
temp_dir="$4"
section="$5"
verbose="$6"

# Create a unique ID for this download
id=$(echo "$url" | md5sum | cut -d' ' -f1)
filename=$(basename "$url" | cut -d'?' -f1)

# Create destination directory
mkdir -p "$comfyui_dir/$dest"

# Set wget options
if [ "$verbose" = "true" ]; then
  wget_opts="-c"
else
  wget_opts="-q -c"
fi

# Perform the download
if cd "$comfyui_dir" && wget $wget_opts "$url" -P "./$dest" > "$temp_dir/logs/$id.log" 2>&1; then
  echo "$dest/$filename" > "$temp_dir/success/$id"
else
  echo "$dest/$filename" > "$temp_dir/fail/$id"
  echo "$url" >> "$temp_dir/fail/$id"
  echo "$section" > "$temp_dir/sections/$id"
fi
EOF

chmod +x "$DOWNLOAD_SCRIPT"

# Create a list of download commands
DOWNLOAD_LIST_FILE="$TEMP_DIR/downloads.txt"
touch "$DOWNLOAD_LIST_FILE"

# Read the download list and create download commands
CURRENT_SECTION="Uncategorized"
TOTAL_DOWNLOADS=0

while read -r line; do
  # Handle section comments
  if [[ "$line" == \#* ]]; then
    CURRENT_SECTION="$line"
    continue
  fi

  # Skip empty lines
  if [[ -z "$line" ]]; then
    continue
  fi

  # Split the line by pipe character to get URL and destination
  url=$(echo "$line" | cut -d'|' -f1)
  dest=$(echo "$line" | cut -d'|' -f2)

  # Add to download list
  echo "$url|$dest|$CURRENT_SECTION" >>"$DOWNLOAD_LIST_FILE"
  TOTAL_DOWNLOADS=$((TOTAL_DOWNLOADS + 1))
done <"$DOWNLOAD_LIST"

echo "Prepared $TOTAL_DOWNLOADS downloads"

# Function to process the download list in batches
process_downloads() {
  local batch_size="$1"
  local current=0

  while read -r entry; do
    url=$(echo "$entry" | cut -d'|' -f1)
    dest=$(echo "$entry" | cut -d'|' -f2)
    section=$(echo "$entry" | cut -d'|' -f3)

    "$DOWNLOAD_SCRIPT" "$url" "$dest" "$COMFYUI_DIR" "$TEMP_DIR" "$section" "$VERBOSE" &

    current=$((current + 1))
    if [ "$current" -ge "$batch_size" ]; then
      wait
      current=0
    fi
  done <"$DOWNLOAD_LIST_FILE"

  # Wait for any remaining downloads
  wait
}

# Start the downloads
echo "Starting downloads with $MAX_PARALLEL_DOWNLOADS parallel processes..."
process_downloads "$MAX_PARALLEL_DOWNLOADS"

# Count results
SUCCESS_COUNT=$(ls -1 "$SUCCESS_DIR" 2>/dev/null | wc -l)
FAILURE_COUNT=$(ls -1 "$FAIL_DIR" 2>/dev/null | wc -l)

# Process and display results
echo ""
echo "Download Results:"
echo "-----------------"

if [ "$SUCCESS_COUNT" -gt 0 ]; then
  echo "✓ Successfully downloaded $SUCCESS_COUNT models"

  if [ "$VERBOSE" = true ]; then
    echo ""
    echo "Successful Downloads:"
    echo "--------------------"
    for file in "$SUCCESS_DIR"/*; do
      cat "$file"
    done
  fi
fi

# Collect failed downloads
if [ "$FAILURE_COUNT" -gt 0 ]; then
  echo ""
  echo "✗ Failed Downloads: $FAILURE_COUNT"
  echo "--------------------"

  for file in "$FAIL_DIR"/*; do
    id=$(basename "$file")
    path=$(head -1 "$file")
    url=$(tail -1 "$file")
    log_file="$LOG_DIR/$id.log"

    echo "$path --> Failed"
    echo "  URL: $url"

    if [ -f "$log_file" ]; then
      echo "  Error details:"
      grep -i "error\|failed\|permission denied\|not found\|forbidden\|refused\|timeout\|no route" "$log_file" | head -3 | sed 's/^/    /'
      echo ""
    fi
  done

  echo "WARNING: $FAILURE_COUNT downloads failed. See details above."
else
  echo ""
  echo "✓ All downloads completed successfully!"
fi

# Generate model report
REPORT_FILE="$COMFYUI_DIR/model-report.txt"
echo "ComfyUI Model Installation Report" >"$REPORT_FILE"
echo "Generated on: $(date)" >>"$REPORT_FILE"
echo "----------------------------------------" >>"$REPORT_FILE"
echo "" >>"$REPORT_FILE"

# Add the IPAdapter special case models to the report
echo "SPECIAL MODELS (IP-ADAPTER)" >>"$REPORT_FILE"
echo "------------------------" >>"$REPORT_FILE"
for pair in "${ipa_special_models[@]}"; do
  dest=$(echo "$pair" | cut -d'|' -f2)
  filename=$(basename "$dest")
  dir=$(dirname "$dest")

  if [ -f "$COMFYUI_DIR/$dest" ]; then
    filesize=$(du -h "$COMFYUI_DIR/$dest" | cut -f1)
    echo "✓ $filename ($filesize)" >>"$REPORT_FILE"
  else
    url=$(echo "$pair" | cut -d'|' -f1)
    echo "✗ $filename - FAILED" >>"$REPORT_FILE"
    echo "  URL: $url" >>"$REPORT_FILE"
  fi
done
echo "" >>"$REPORT_FILE"

# Create directory-based collections for the report
declare -A MODELS_BY_DIR
declare -A FAILED_BY_DIR

# Collect successful downloads by directory
for file in "$SUCCESS_DIR"/*; do
  if [ -f "$file" ]; then
    content=$(cat "$file")
    # Extract directory and filename
    if [[ "$content" =~ ([^/]+/[^/]+)/([^/]+)$ ]]; then
      dir="${BASH_REMATCH[1]}"
      filename="${BASH_REMATCH[2]}"

      # Add to our directory-based collection
      if [[ -z "${MODELS_BY_DIR[$dir]}" ]]; then
        MODELS_BY_DIR[$dir]="$filename"
      else
        MODELS_BY_DIR[$dir]="${MODELS_BY_DIR[$dir]}"$'\n'"$filename"
      fi
    fi
  fi
done

# Collect failed downloads by directory and section
declare -A SECTION_FAILURES

for file in "$FAIL_DIR"/*; do
  if [ -f "$file" ]; then
    id=$(basename "$file")
    path=$(head -1 "$file")
    url=$(tail -1 "$file")

    # Get section if available
    section="Uncategorized Models"
    if [ -f "$SECTION_DIR/$id" ]; then
      section=$(cat "$SECTION_DIR/$id")
    fi

    # Extract directory and filename
    if [[ "$path" =~ ([^/]+/[^/]+)/([^/]+)$ ]]; then
      dir="${BASH_REMATCH[1]}"
      filename="${BASH_REMATCH[2]}"

      # Get error message
      error_msg=""
      log_file="$LOG_DIR/$id.log"
      if [ -f "$log_file" ]; then
        error_msg=$(grep -i "error\|failed\|permission denied\|not found\|forbidden\|refused\|timeout\|no route" "$log_file" | head -3)
        if [ -z "$error_msg" ]; then
          error_msg=$(tail -3 "$log_file")
        fi
      fi

      # Create an entry with all the information
      entry="$dir|$filename|$url|$error_msg"

      # Add to our section-based collection
      if [[ -z "${SECTION_FAILURES[$section]}" ]]; then
        SECTION_FAILURES[$section]="$entry"
      else
        SECTION_FAILURES[$section]="${SECTION_FAILURES[$section]}"$'\n'"$entry"
      fi
    fi
  fi
done

# Add successfully installed models organized by directory
echo "SUCCESSFULLY INSTALLED MODELS" >>"$REPORT_FILE"
echo "---------------------------" >>"$REPORT_FILE"
for dir in "${!MODELS_BY_DIR[@]}"; do
  echo "Directory: $dir" >>"$REPORT_FILE"
  echo "-----------------" >>"$REPORT_FILE"

  # List each file with its size
  echo "${MODELS_BY_DIR[$dir]}" | while read -r file; do
    if [ ! -z "$file" ]; then
      # Get file size if the file exists
      if [ -f "$COMFYUI_DIR/$dir/$file" ]; then
        filesize=$(du -h "$COMFYUI_DIR/$dir/$file" | cut -f1)
        echo "✓ $file ($filesize)" >>"$REPORT_FILE"
      else
        echo "✓ $file (size unknown)" >>"$REPORT_FILE"
      fi
    fi
  done
  echo "" >>"$REPORT_FILE"
done

# Add failed downloads organized by section with error messages
if [ "$FAILURE_COUNT" -gt 0 ]; then
  echo "FAILED DOWNLOADS (WITH ERROR DETAILS)" >>"$REPORT_FILE"
  echo "---------------------------------" >>"$REPORT_FILE"

  # Now output by section
  for section in "${!SECTION_FAILURES[@]}"; do
    echo "$section" >>"$REPORT_FILE"
    echo "${section//?/-}" >>"$REPORT_FILE"
    echo "" >>"$REPORT_FILE"

    # Keep track of directories in this section
    declare -A SECTION_DIRS

    # First pass to identify directories
    echo "${SECTION_FAILURES[$section]}" | while read -r entry; do
      if [ ! -z "$entry" ]; then
        dir=$(echo "$entry" | cut -d'|' -f1)
        SECTION_DIRS["$dir"]=1
      fi
    done

    # Second pass to output by directory
    for dir in "${!SECTION_DIRS[@]}"; do
      echo "Directory: $dir" >>"$REPORT_FILE"
      echo "-----------------" >>"$REPORT_FILE"

      # Process entries for this directory
      echo "${SECTION_FAILURES[$section]}" | while read -r entry; do
        if [ ! -z "$entry" ]; then
          entry_dir=$(echo "$entry" | cut -d'|' -f1)

          if [ "$entry_dir" = "$dir" ]; then
            file=$(echo "$entry" | cut -d'|' -f2)
            url=$(echo "$entry" | cut -d'|' -f3)
            error_msg=$(echo "$entry" | cut -d'|' -f4-)

            echo "✗ $file" >>"$REPORT_FILE"
            echo "  URL: $url" >>"$REPORT_FILE"

            if [ ! -z "$error_msg" ]; then
              echo "  Error details:" >>"$REPORT_FILE"
              echo "$error_msg" | sed 's/^/    /' >>"$REPORT_FILE"
            else
              echo "  Error details: No specific error message captured" >>"$REPORT_FILE"
            fi
            echo "" >>"$REPORT_FILE"
          fi
        fi
      done
      echo "" >>"$REPORT_FILE"
    done
  done
fi

# Add summary to the report
echo "SUMMARY" >>"$REPORT_FILE"
echo "-------" >>"$REPORT_FILE"
echo "Total models attempted: $TOTAL_DOWNLOADS" >>"$REPORT_FILE"
echo "Successfully downloaded: $SUCCESS_COUNT" >>"$REPORT_FILE"
echo "Failed downloads: $FAILURE_COUNT" >>"$REPORT_FILE"
echo "" >>"$REPORT_FILE"
echo "Report generated by ComfyUI Enhanced Model Downloader" >>"$REPORT_FILE"

# Generate a failed_downloads.txt for retrying just the failed downloads
if [ "$FAILURE_COUNT" -gt 0 ]; then
  RETRY_FILE="$COMFYUI_DIR/failed_downloads.txt"
  echo "# Failed Downloads - Retry File" >"$RETRY_FILE"
  echo "# Generated on: $(date)" >>"$RETRY_FILE"
  echo "# Run with: ./install-models.sh --failed" >>"$RETRY_FILE"
  echo "" >>"$RETRY_FILE"

  # Track the current section for output
  current_section=""

  # Read the original download list
  while read -r line; do
    # Handle section comments
    if [[ "$line" == \#* ]]; then
      current_section="$line"
      # Don't output section headers until we know we have content for that section
      continue
    fi

    # Skip empty lines
    if [[ -z "$line" ]]; then
      continue
    fi

    # Split the line by pipe character to get URL and destination
    url=$(echo "$line" | cut -d'|' -f1)
    dest=$(echo "$line" | cut -d'|' -f2)

    # Get filename for checking
    filename=$(basename "$url" | cut -d'?' -f1)
    full_path="$COMFYUI_DIR/$dest/$filename"

    # If file doesn't exist, add it to the retry file
    if [ ! -f "$full_path" ]; then
      # If we haven't output this section header yet, do it now
      if [ ! -z "$current_section" ]; then
        echo "$current_section" >>"$RETRY_FILE"
        current_section="" # Reset so we don't output it again
      fi

      echo "$line" >>"$RETRY_FILE"
    fi
  done <"$DOWNLOAD_LIST"

  echo "Created retry file: $RETRY_FILE"
fi

# Create installed_model_downloads.txt with only the successful models
INSTALLED_FILE="$COMFYUI_DIR/installed_model_downloads.txt"
echo "# Successfully Downloaded Models" >"$INSTALLED_FILE"
echo "# Generated on: $(date)" >>"$INSTALLED_FILE"
echo "# This file contains only models that were successfully downloaded" >>"$INSTALLED_FILE"
echo "" >>"$INSTALLED_FILE"

# Track the current section
current_section=""
section_has_content=false

# Read the original download list
while read -r line; do
  # Handle section comments
  if [[ "$line" == \#* ]]; then
    # If the previous section had content, add a blank line
    if [ "$section_has_content" = true ]; then
      echo "" >>"$INSTALLED_FILE"
    fi

    current_section="$line"
    section_has_content=false

    # Write the section header
    echo "$current_section" >>"$INSTALLED_FILE"
    continue
  fi

  # Skip empty lines
  if [[ -z "$line" ]]; then
    continue
  fi

  # Split the line by pipe character to get URL and destination
  url=$(echo "$line" | cut -d'|' -f1)
  dest=$(echo "$line" | cut -d'|' -f2)

  # Get filename for checking
  filename=$(basename "$url" | cut -d'?' -f1)
  full_path="$COMFYUI_DIR/$dest/$filename"

  # Check for special IPAdapter models which have different filenames
  found_special=false
  for pair in "${ipa_special_models[@]}"; do
    special_url=$(echo "$pair" | cut -d'|' -f1)
    special_dest=$(echo "$pair" | cut -d'|' -f2)

    if [ "$special_url" = "$url" ]; then
      if [ -f "$COMFYUI_DIR/$special_dest" ]; then
        echo "$line" >>"$INSTALLED_FILE"
        section_has_content=true
        found_special=true
        break
      fi
    fi
  done

  # If it's not a special model and the file exists, add it
  if [ "$found_special" = false ] && [ -f "$full_path" ]; then
    echo "$line" >>"$INSTALLED_FILE"
    section_has_content=true
  fi
done <"$DOWNLOAD_LIST"

echo "Created installed model downloads file: $INSTALLED_FILE"

# Clean up
rm -rf "$TEMP_DIR"

echo ""
echo "Summary: $SUCCESS_COUNT successful, $FAILURE_COUNT failed out of $TOTAL_DOWNLOADS total"
echo "A detailed model report has been generated at: $REPORT_FILE"

show_progress "Download Complete!"
echo "All available models have been downloaded to $COMFYUI_DIR/models/"
echo "IPAdapter models have been properly renamed for the Unified Loader."
echo ""

if [ "$FAILURE_COUNT" -gt 0 ]; then
  echo "Some downloads failed. The following files have been created to help you:"
  echo "1. $REPORT_FILE - Detailed model installation report with error messages"
  echo "2. $RETRY_FILE - Contains only the failed downloads for easy retry"
  echo "3. $INSTALLED_FILE - Contains only the successfully downloaded models"
  echo ""
  echo "To retry failed downloads, run: ./install-models.sh --failed"
else
  echo "All downloads completed successfully!"
  echo "A detailed model report has been generated at: $REPORT_FILE"
  echo "A list of all installed models has been created at: $INSTALLED_FILE"
fi

echo "You can now start using ComfyUI with all the downloaded models."
