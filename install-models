#!/bin/bash
set -e

# Script to download all ComfyUI models at the start of a session
echo "=== ComfyUI Model Downloader ==="

# Get the directory where the script is located
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# Default values
TEST_MODE=false
COMFYUI_DIR=""

# Parse command-line arguments
for arg in "$@"; do
  if [ "$arg" = "--test" ]; then
    TEST_MODE=true
  elif [ "$arg" != "--test" ]; then
    COMFYUI_DIR="$arg"
  fi
done

# If no directory was specified, use current directory
if [ -z "$COMFYUI_DIR" ]; then
  COMFYUI_DIR=$(pwd)
fi

# Determine optimal number of parallel downloads based on CPU cores
# Use 75% of available cores by default, minimum 4, maximum 32
AVAILABLE_CORES=$(nproc)
MAX_PARALLEL_DOWNLOADS=$((AVAILABLE_CORES * 3 / 4))
MAX_PARALLEL_DOWNLOADS=$((MAX_PARALLEL_DOWNLOADS < 4 ? 4 : MAX_PARALLEL_DOWNLOADS))
MAX_PARALLEL_DOWNLOADS=$((MAX_PARALLEL_DOWNLOADS > 32 ? 32 : MAX_PARALLEL_DOWNLOADS))

# Error handling function
handle_error() {
  echo "ERROR: $1"
  echo "Download failed. Please check the error message above."
  exit 1
}

# Function to show progress
show_progress() {
  local msg="$1"
  echo ""
  echo "---------------------------------------------------"
  echo "  $msg"
  echo "---------------------------------------------------"
}

# Check if the specified directory is a ComfyUI directory (unless in test mode)
if [ "$TEST_MODE" = false ]; then
  if [ ! -d "$COMFYUI_DIR/models" ] || [ ! -d "$COMFYUI_DIR/comfy" ]; then
    echo "ERROR: The specified directory does not appear to be a ComfyUI installation."
    echo "Please specify a valid ComfyUI directory as an argument."
    echo "To bypass this check for testing, use the --test flag."
    exit 1
  fi
else
  echo "Running in TEST MODE - ComfyUI directory check bypassed"
  echo "Using directory: $COMFYUI_DIR"
fi

show_progress "Creating model directories"
# Create required directories
mkdir -p "$COMFYUI_DIR/models/checkpoints"
mkdir -p "$COMFYUI_DIR/models/clip_vision"
mkdir -p "$COMFYUI_DIR/models/vae"
mkdir -p "$COMFYUI_DIR/models/loras"
mkdir -p "$COMFYUI_DIR/models/controlnet"
mkdir -p "$COMFYUI_DIR/models/upscale_models"
mkdir -p "$COMFYUI_DIR/models/facerestore_models"
mkdir -p "$COMFYUI_DIR/models/ipadapter"
mkdir -p "$COMFYUI_DIR/models/instantid/antelopev2"

cd "$COMFYUI_DIR"

# ====================================================
# IPAdapter Special Case Handling - Processed Sequentially
# ====================================================
show_progress "Downloading IPAdapter models that require special naming"

# Array of source URLs and destination filenames
declare -a ipa_special_models=(
  "https://huggingface.co/h94/IP-Adapter/resolve/main/models/image_encoder/model.safetensors|models/clip_vision/CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors"
  "https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/image_encoder/model.safetensors|models/clip_vision/CLIP-ViT-bigG-14-laion2B-39B-b160k.safetensors"
  "https://huggingface.co/Kwai-Kolors/Kolors-IP-Adapter-Plus/resolve/main/image_encoder/pytorch_model.bin|models/clip_vision/clip-vit-large-patch14-336.bin"
  "https://huggingface.co/Kwai-Kolors/Kolors-IP-Adapter-Plus/resolve/main/ip_adapter_plus_general.bin|models/ipadapter/Kolors-IP-Adapter-Plus.bin"
  "https://huggingface.co/Kwai-Kolors/Kolors-IP-Adapter-FaceID-Plus/resolve/main/ipa-faceid-plus.bin|models/ipadapter/Kolors-IP-Adapter-FaceID-Plus.bin"
)

# Process each URL and destination pair - doing these sequentially for better visibility
echo "Processing ${#ipa_special_models[@]} special case IPAdapter models sequentially..."

for pair in "${ipa_special_models[@]}"; do
  url=$(echo "$pair" | cut -d'|' -f1)
  dest=$(echo "$pair" | cut -d'|' -f2)

  # Get filename for better logging
  filename=$(basename "$dest")
  full_path="$COMFYUI_DIR/$dest"

  echo "Downloading to $dest ..."
  if wget -q -c "$url" -O "$full_path" 2>/dev/null; then
    echo "$dest <-- Complete"
  else
    echo "$dest <-- Failed"
    echo "$url"
  fi
done

echo "All IPAdapter special case models have been processed."

# ====================================================
# Main Model Downloads - With Clean Success/Failure Reporting
# ====================================================
show_progress "Starting main model downloads"
echo "Using $MAX_PARALLEL_DOWNLOADS parallel downloads (based on $AVAILABLE_CORES CPU cores)"

# Check if download list exists
DOWNLOAD_LIST="$SCRIPT_DIR/model_downloads.txt"
if [ ! -f "$DOWNLOAD_LIST" ]; then
  echo "ERROR: $DOWNLOAD_LIST not found!"
  echo "Please ensure the model_downloads.txt file is in the same directory as this script."
  exit 1
fi

# Create a temporary file to hold download commands
DOWNLOAD_COMMANDS_FILE=$(mktemp)
# Create a temporary directory to store success/failure logs
TEMP_LOG_DIR=$(mktemp -d)

# Read the download list and create wget commands
while read -r line; do
  # Skip empty lines and comments
  if [[ -z "$line" || "$line" == \#* ]]; then
    # If it's a comment, print it as a section header
    if [[ "$line" == \#* ]]; then
      echo ""
      echo "$line"
    fi
    continue
  fi

  # Split the line by pipe character to get URL and destination
  url=$(echo "$line" | cut -d'|' -f1)
  dest=$(echo "$line" | cut -d'|' -f2)

  # Get filename for tracking
  filename=$(basename "$url" | cut -d'?' -f1)

  # Create a unique log identifier
  log_id=$(echo "$url" | md5sum | cut -d' ' -f1)

  # Add the download command to our commands file with success/failure reporting
  echo "cd \"$COMFYUI_DIR\" && wget -q -c \"$url\" -P \"./$(echo $dest)\" > /dev/null 2>&1 && echo \"$dest/$filename <-- Complete\" > \"$TEMP_LOG_DIR/$log_id.success\" || { echo \"$dest/$filename <-- Failed\" > \"$TEMP_LOG_DIR/$log_id.fail\"; echo \"$url\" >> \"$TEMP_LOG_DIR/$log_id.fail\"; }" >>"$DOWNLOAD_COMMANDS_FILE"
done <"$DOWNLOAD_LIST"

# Count total downloads
TOTAL_DOWNLOADS=$(wc -l <"$DOWNLOAD_COMMANDS_FILE")
echo "Starting $TOTAL_DOWNLOADS downloads with $MAX_PARALLEL_DOWNLOADS parallel processes"
echo "Download results will be reported when complete."

# Execute downloads with xargs for better parallelism
cat "$DOWNLOAD_COMMANDS_FILE" | xargs -P "$MAX_PARALLEL_DOWNLOADS" -I {} bash -c "{}"

# Process and display results
echo ""
echo "Download Results:"
echo "-----------------"

# Print successful downloads
if ls "$TEMP_LOG_DIR"/*.success 1>/dev/null 2>&1; then
  cat "$TEMP_LOG_DIR"/*.success | sort
fi

# Print failed downloads
if ls "$TEMP_LOG_DIR"/*.fail 1>/dev/null 2>&1; then
  echo ""
  echo "Failed Downloads:"
  echo "-----------------"
  cat "$TEMP_LOG_DIR"/*.fail
  FAILURE_COUNT=$(ls -1 "$TEMP_LOG_DIR"/*.fail 2>/dev/null | wc -l)
  echo ""
  echo "WARNING: $FAILURE_COUNT downloads failed. See details above."
else
  echo ""
  echo "âœ“ All downloads completed successfully!"
fi

# Clean up
rm -rf "$TEMP_LOG_DIR"
rm "$DOWNLOAD_COMMANDS_FILE"

show_progress "Download Complete!"
echo "All models have been downloaded to $COMFYUI_DIR/models/"
echo "IPAdapter models have been properly renamed for the Unified Loader."
echo "NOTE: ReActor models installation has been removed from this script."
echo "To install ReActor models, please run the separate reactorinstall script."
echo "You can now start using ComfyUI with all the downloaded models."
